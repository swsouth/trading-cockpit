# Sub-Agent Usage Protocol

This document defines when to invoke specialized sub-agents vs. handling tasks directly, to optimize for both quality and efficiency (token usage, latency).

## Core Principle: Use Agents Sparingly

**Default behavior**: Handle most tasks directly without spawning agents.

**Invoke agents only when**:
1. Task requires deep domain expertise beyond general knowledge
2. Task is complex enough to justify the overhead (multi-step analysis, comprehensive review)
3. Output requires formal structure/deliverables (reports, specifications, checklists)
4. Risk of error is high without specialized knowledge

---

## Agent Invocation Decision Tree

### ğŸ”µ Market Data & Integrity Agent

**INVOKE when:**
- âœ… Investigating data anomalies affecting multiple symbols or time periods
- âœ… Designing data pipeline for new vendor/exchange integration
- âœ… Suspected corporate action errors (splits, dividends) requiring forensic analysis
- âœ… Creating formal data quality framework or SLA monitoring system
- âœ… Data version divergence causing backtest discrepancies (needs diff analysis)
- âœ… Building reproducible data snapshots for audit/compliance

**HANDLE DIRECTLY when:**
- âŒ Simple data fetch or single symbol validation ("Is AAPL data current?")
- âŒ Basic OHLCV data structure questions
- âŒ Single missing bar or small gap (straightforward query issue)
- âŒ General questions about data vendors ("Does Alpaca have crypto data?")
- âŒ Reading/explaining existing data quality reports

**Examples:**
- âŒ Direct: "What's the latest AAPL close price?" â†’ Simple query, no agent needed
- âœ… Agent: "Validate all S&P 500 data for the last 2 years; identify splits, gaps, and anomalies; provide health report" â†’ Complex, multi-symbol, formal deliverable
- âŒ Direct: "How do I handle stock splits in my code?" â†’ General guidance, no agent
- âœ… Agent: "Build split adjustment pipeline for our historical database with versioning and rollback" â†’ System design, needs formal spec

---

### ğŸŸ¢ Strategy & Signal Engineering Agent

**INVOKE when:**
- âœ… Converting trading concept into formal, production-ready signal specification
- âœ… Designing multi-factor signal with regime filters, pre-trade checks, and position sizing
- âœ… Building comprehensive unit test suite for signal logic
- âœ… Creating signal suppression rules with edge case handling
- âœ… Translating research findings into deployable code with full documentation
- âœ… Designing position sizing formulas with caps and volatility adjustments

**HANDLE DIRECTLY when:**
- âŒ Conceptual discussion of indicators ("How does RSI work?")
- âŒ Simple signal logic questions ("Should I use 20 or 50 period SMA?")
- âŒ Basic parameter recommendations for common indicators
- âŒ Explaining existing signal specs or code
- âŒ Quick pre-trade check suggestions (can provide directly)

**Examples:**
- âŒ Direct: "What's a good stop-loss for swing trading?" â†’ General guidance
- âœ… Agent: "Create a complete signal spec for volatility breakout strategy with Bollinger Bands, volume filters, ATR-based stops, and regime detection" â†’ Full specification needed
- âŒ Direct: "Should I add ADX to my trend-following signal?" â†’ Straightforward recommendation
- âœ… Agent: "Design regime classification system using ADX, volatility, and trend structure; integrate with existing signal pipeline" â†’ Complex system design

---

### ğŸŸ£ Research & Backtesting Scientist Agent

**INVOKE when:**
- âœ… Formal strategy validation with OOS testing, walk-forward analysis, and go/no-go decision
- âœ… Comprehensive overfitting analysis with parameter sensitivity testing
- âœ… Designing research protocol for new hypothesis with sample splits and bias checks
- âœ… Full distributional risk analysis (drawdowns, tail risk, regime stress tests)
- âœ… Investigating significant backtest performance divergence (requires forensic analysis)
- âœ… Creating formal evidence brief for strategy deployment decision

**HANDLE DIRECTLY when:**
- âŒ Interpreting single performance metric ("Is Sharpe 1.5 good?")
- âŒ Basic backtest results explanation
- âŒ Simple bias questions ("What is look-ahead bias?")
- âŒ Rough directional guidance on strategy viability
- âŒ Reading/summarizing existing backtest reports

**Examples:**
- âŒ Direct: "My strategy has 60% win rate. Is that good?" â†’ Simple interpretation
- âœ… Agent: "Validate my EMA crossover strategy: run OOS tests, check for overfitting, model transaction costs, analyze drawdowns, provide go/no-go recommendation" â†’ Comprehensive validation
- âŒ Direct: "What's the difference between in-sample and out-of-sample testing?" â†’ Educational explanation
- âœ… Agent: "Design 10-year walk-forward test framework with rolling windows for my mean-reversion strategy; include Monte Carlo simulation" â†’ Complex protocol design

---

### ğŸ”´ Trading Specialist SME Agent

**INVOKE when:**
- âœ… Generating trade recommendations with full setup (entry, stop, target, sizing, caveats)
- âœ… Comprehensive feature review (viability, feasibility, functionality, value) with RICE scoring
- âœ… Deep technical analysis across multiple timeframes with regime assessment
- âœ… Reviewing backtest for robustness, bias risks, and deployment readiness
- âœ… Complex risk management scenario analysis (correlation, concentration, stress tests)
- âœ… Translating advanced TA concepts into actionable user guidance

**HANDLE DIRECTLY when:**
- âŒ Simple indicator explanations or calculations
- âŒ Basic trading terminology definitions
- âŒ General market commentary without specific trade setup
- âŒ Straightforward feature questions ("Should we add price alerts?")
- âŒ Basic risk management principles (position sizing formulas, stop-loss concepts)

**Examples:**
- âŒ Direct: "What's a good risk percentage per trade?" â†’ Standard guidance (1-2%)
- âœ… Agent: "Analyze TSLA for swing trade opportunities; provide full setup with confidence rating, regime assessment, and position sizing for $50K account" â†’ Complete trade analysis
- âŒ Direct: "Should we add a volatility filter?" â†’ General recommendation
- âœ… Agent: "Review our new multi-indicator screener feature for viability, feasibility, functionality, and value; provide RICE score and deployment recommendations" â†’ Formal feature review

---

## Efficiency Guidelines

### 1. Batch Related Tasks

Instead of invoking agents multiple times for related tasks, batch them:

**âŒ Inefficient:**
```
User: "Validate AAPL data"
[Agent invoked]
User: "Now validate TSLA data"
[Agent invoked again]
User: "And GOOGL"
[Agent invoked third time]
```

**âœ… Efficient:**
```
User: "Validate AAPL, TSLA, and GOOGL data for the last 90 days"
[Single agent invocation handles all three]
```

### 2. Use Direct Answers for Quick Questions

Most questions can be answered directly without agents:
- Indicator calculations
- Basic strategy concepts
- Feature suggestions
- Simple debugging help
- General trading education

### 3. Escalate to Agents for Deliverables

Invoke agents when you need formal outputs:
- Specification documents
- Health/validation reports
- Go/No-Go decision memos
- Test frameworks
- Risk analysis reports

### 4. Consider Complexity Threshold

**Simple (handle directly)**: Single-step task, < 5 minute response, no formal structure needed

**Complex (invoke agent)**: Multi-step analysis, > 10 minute response, formal deliverable with sections/checklists

---

## Token & Latency Estimates

### Agent Size (approximate tokens)
- Market Data & Integrity: ~11,000 tokens
- Strategy & Signal Engineering: ~13,000 tokens
- Research & Backtesting Scientist: ~16,000 tokens
- Trading Specialist SME: ~9,000 tokens

### Cost Consideration
- Agent invocation adds 9K-16K tokens to context (input cost)
- Agent responses can be 1K-5K tokens (output cost)
- **Total overhead per agent**: ~10K-20K tokens

**Rule of thumb**: Only invoke agent if the value of specialized analysis exceeds the cost of ~$0.30-$0.60 per invocation (at current API rates).

### Latency Impact
- Agent spawning adds ~10-30 seconds to response time
- Use agents when thoroughness matters more than speed
- For time-sensitive questions, handle directly

---

## Quick Reference Chart

| Task Type | Complexity | Agent Needed? | Example |
|-----------|------------|---------------|---------|
| Data validation (single symbol) | Low | âŒ No | "Is AAPL data current?" |
| Data pipeline design | High | âœ… Yes | "Design Coinbase WebSocket ingestion pipeline" |
| Signal concept discussion | Low | âŒ No | "Should I use MACD?" |
| Signal spec creation | High | âœ… Yes | "Create formal spec for breakout signal with all filters" |
| Backtest result interpretation | Low | âŒ No | "Is 1.5 Sharpe good?" |
| Full strategy validation | High | âœ… Yes | "Run OOS tests, check overfitting, provide go/no-go" |
| Simple trade idea | Low | âŒ No | "What's your view on BTC?" |
| Complete trade setup | High | âœ… Yes | "Generate swing trade setup for AAPL with full risk management" |

---

## When in Doubt: Ask First

If uncertain whether to invoke an agent:

**User asks**: "Can you help me with my moving average strategy?"

**Assistant responds**: "I can help with that! To give you the most efficient answer:
- If you need general guidance on parameters or logic, I can answer directly (faster)
- If you want a complete signal specification with tests and documentation, I'll use the strategy-signal-engineering agent (more thorough but slower)

Which would be most helpful?"

This lets the user decide based on their urgency and needs.

---

## Summary: The 3 Questions Test

Before invoking an agent, ask:

1. **Is this complex enough to require deep domain expertise?**
   - No â†’ Handle directly
   - Yes â†’ Continue

2. **Does this need a formal deliverable (report, spec, checklist)?**
   - No â†’ Handle directly (unless very complex)
   - Yes â†’ Continue

3. **Is the value of specialized analysis worth ~30 seconds latency and ~$0.50 cost?**
   - No â†’ Handle directly
   - Yes â†’ Invoke agent

**If all 3 are "Yes" â†’ Invoke agent. Otherwise â†’ Handle directly.**

---

## Maintenance

Review this protocol quarterly:
- Monitor agent invocation patterns
- Identify unnecessary invocations (could have been handled directly)
- Update examples based on common use cases
- Adjust complexity thresholds as agents evolve
